\documentclass[a4paper,10pt]{article}
\pdfoptionpdfminorversion=5
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{multicol}
\usepackage{xcolor,colortbl}
\usepackage{datetime}
\usepackage{xfrac}

\newcommand{\mc}[2]{\multicolumn{#1}{c}{#2}}
\definecolor{Gray}{gray}{0.85}
\newcolumntype{a}{>{\columncolor{Gray}}c}
\newcolumntype{b}{>{\columncolor{white}}c}
\newcolumntype{R}{>{\columncolor{lime}}c}
\newcolumntype{B}{>{\columncolor{pink}}c}
\usepackage{diagbox}

\usepackage[numbers]{natbib}

\usepackage[utf8]{inputenc}
\usepackage{array,multirow,graphicx}
\usepackage{graphics}
\usepackage{color}
\usepackage{ifpdf}
\ifpdf
\DeclareGraphicsRule{*}{mps}{*}{}
\fi
\usepackage[utf8]{inputenc}

\hoffset = 0pt
\voffset = 0pt
\oddsidemargin = 0pt
\headheight = 15pt
\footskip = 30pt
\topmargin = 0pt
\marginparsep = 5pt
\headsep =25pt
\marginparwidth = 54pt
\marginparpush = 7pt
\textheight = 621pt %621/
\textwidth = 500pt

% Default fixed font does not support bold face
\DeclareFixedFont{\ttb}{T1}{txtt}{bx}{n}{12} % for bold
\DeclareFixedFont{\ttm}{T1}{txtt}{m}{n}{12}  % for normal

\newcommand{\I}{\ensuremath{\mathbb{I}}}
\newcommand{\R}{\ensuremath{\mathbb{R}}}

\newcommand{\norm}[1]{\ensuremath{\left\|#1\right\|}}
\newcommand{\seminorm}[1]{\ensuremath{\left|#1\right|}}
\newcommand{\dual}[2]{\ensuremath{\langle#1, #2 \rangle}}

\newcommand{\inner}[2]{\ensuremath{\left(#1, #2\right)}}
\newcommand{\Inner}[2]{\ensuremath{\left(\left(#1, #2\right)\right)}}

\newcommand{\deriv}[2]{\ensuremath{\frac{\mathrm{d}#1}{\mathrm{d}#2}}}
\newcommand{\meas}[1]{\ensuremath{\,\mathrm{d}#1}}
\newcommand{\Div}[1] {\ensuremath{\text{div}#1}}
\newcommand{\Grad}[1]{\ensuremath{\text{grad}#1}}
\newcommand{\Curl}[1]{\ensuremath{\text{curl}#1}}
\newcommand{\jump}[1]{\ensuremath{[\![#1]\!]} }

\newcommand{\citeneed}{\ensuremath{^\text{\textcolor{blue}{cite?}}}}

\usepackage{mathtools}
\newcommand{\eqdef}{\mathrel{\mathop=}:} 

\newcommand{\mm}{\ensuremath{\mathbf{m}}}
\newcommand{\Vp}{\ensuremath{V_{\mathcal{P}}}}
\newcommand{\Vb}{\ensuremath{V_{\mathcal{B}}}}
\newcommand{\Ep}{\ensuremath{E_{\mathcal{P}}}}
\newcommand{\Eb}{\ensuremath{E_{\mathcal{B}}}}

%matrices
\newcommand{\Ap}{\ensuremath{\mathbb{A}_{\mathcal{P}}}}
\newcommand{\Ab}{\ensuremath{\mathbb{A}_{\mathcal{B}}}}
\newcommand{\Bp}{\ensuremath{\mathbb{B}_{\mathcal{P}}}}
\newcommand{\Bb}{\ensuremath{\mathbb{B}_{\mathcal{B}}}}
\newcommand{\Amat}{\ensuremath{\mathbb{A}}}
\newcommand{\Bmat}{\ensuremath{\mathbb{B}}}
\newcommand{\Bmatt}{\ensuremath{\mathbb{B}^{\text{T}}}}
\newcommand{\Mmat}{\ensuremath{\mathbb{M}}}
\newcommand{\Nmat}{\ensuremath{\mathbb{N}}}

\newcommand{\Ammatt}{\ensuremath{\tilde{\mathbb{A}}_m}}              %
\newcommand{\Mmmatt}{\ensuremath{\tilde{\mathbb{M}}_m}}              %
\newcommand{\Ammat}{\ensuremath{\mathbb{A}_m}}               %
\newcommand{\Mmmat}{\ensuremath{\mathbb{M}_m}}               %
\newcommand{\Pmat}{\ensuremath{\mathbb{P}}}                  %
\newcommand{\Pmatt}{\ensuremath{\mathbb{P}^{\text{T}}}}       %

%components
\newcommand{\Apij}[2]{\ensuremath{\left(\mathbb{A}_{\mathcal{P}}\right)_{#1, #2}}}
\newcommand{\Abij}[2]{\ensuremath{\left(\mathbb{A}_{\mathcal{B}}\right)_{#1, #2}}}
\newcommand{\Bpij}[2]{\ensuremath{\left(\mathbb{B}_{\mathcal{P}}\right)_{#1, #2}}}
\newcommand{\Bbij}[2]{\ensuremath{\left(\mathbb{B}_{\mathcal{B}}\right)_{#1, #2}}}
%vectors
\newcommand{\Uvec}{\ensuremath{\mathbf{U}}}
\newcommand{\bvec}{\ensuremath{\mathbf{b}}}
\newcommand{\Pvec}{\ensuremath{\mathbf{P}}}

\newcommand{\up}{\ensuremath{u_{\mathcal{P}}}}
\newcommand{\ub}{\ensuremath{u_{\mathcal{B}}}}
\newcommand{\vp}{\ensuremath{v_{\mathcal{P}}}}
\newcommand{\vb}{\ensuremath{v_{\mathcal{B}}}}
\newcommand{\TODO}[1]{\textcolor{red}{#1}}
\newcommand{\ASK}[1]{\textcolor{blue}{#1}}

\newcommand{\W}[1]{\ensuremath{w\!\left[#1\right]\!}}
\newcommand{\E}[1]{\ensuremath{\epsilon \!\left[#1\right]\!}}
\newcommand{\T}[1]{\ensuremath{\sigma \! \left[#1\right]\!}}

\newcommand{\Tr}[1]{\ensuremath{\text{tr}#1}}
\newcommand*{\defeq}{\mathrel{\vcenter{\baselineskip0.5ex \lineskiplimit0pt
                     \hbox{\scriptsize.}\hbox{\scriptsize.}}}%
                     =}

\usepackage{lipsum}
\usepackage{authblk}
\usepackage{fancyhdr}
\usepackage[colorlinks=true,
            linkcolor=cyan,
            citecolor=gray]{hyperref}

\usepackage{chngcntr}
\counterwithin{table}{subsection}

\DeclareMathOperator{\spn}{span}

% DEBUGGING
\usepackage{lineno}
\linenumbers
%\usepackage{setspace}
%\doublespacing
%
%\pagestyle{fancy}
%
\renewenvironment{abstract}{%
\hfill\begin{minipage}{0.95\textwidth}
\rule{\textwidth}{1pt}}
{\par\noindent\rule{\textwidth}{1pt}\end{minipage}}
%
\makeatletter
\renewcommand\@maketitle{%
\hfill
\begin{minipage}{0.95\textwidth}
\vskip 2em
\let\footnote\thanks 
{\LARGE \@title \par }
\vskip 1.5em
{\large \@author \par}
\end{minipage}
\vskip 1em \par
}
\makeatother
%
\begin{document}
%
%title and author details
\title{\begin{center}
        Connecting FEM and spectral methods
       \end{center}}
\author[1]{MK}
%\author[2]{Name2}
%\affil[1]{Address of author} 
%\affil[2]{Address of second author}
%
\maketitle
%
\begin{abstract}
  For one-dimensional Poisson problem we study a connection between the
  stiffness and mass matrices obtained from a discretization with the finite
  element method using continuous linear Lagrange elements and two discretizations
  with the Galerkin method where the eigenfunctions of the Laplacian and
  combinations of Legendre polynomials are used respectively as the test
  functions. We show that the matrices due to finite element method can be viewed
  as the limit of transformations describing the change of basis. Further, we
  study the limiting behaviour and it is shown that the eigenfunctions lead to
  faster convergence.
\end{abstract}

\section{Introduction}
  % explaing that the methods start from variational formulation, solve that
  % problem by Galerkin method, subspace and lead to matrices. The differences
  % are in how the subspace is constraucted naturally leads to different
  % matrices
  For given data $f$ we consider a problem of finding sufficiently regular
  function $u$ that has zero boundary values and satisfies
  \begin{equation}
    \label{eq:strong}
    u^{\prime\prime} = f
  \end{equation}
  inside the domain $\Omega=\left[-1, 1\right]$. Numerical methods studied here
  are based on a variational formulation of (\ref{eq:strong}) which reads: Find
  $u\in V=H^1_0(\Omega)$ such that
  \begin{equation}
    \label{eq:weak}
    \inner{u^{\prime}}{v^{\prime}} = \inner{f}{v}\quad\forall v\in V.
  \end{equation}
  The methods then solve (\ref{eq:weak}) approximately by the Galerkin method,
  that is, by considering the problem on a finite dimensional subspace
  $V_h\subset V$. If $V_h=\spn\left\{\phi_i\right\}_{i=0}^{n-1}$ the Galerkin
  method leads to a linear system
  \[
    \Amat\Uvec = \bvec
  \]
  for the unknown expansion coefficients of the solution
  $u_h=\sum_{i=0}^{n-1}\Uvec_i \phi_i$. The matrix $\Amat\in\R^{n\times n}$ is
  called the stiffness matrix and has the entries given by
  \[
    \Amat_{i, j} = \inner{\phi_j^{\prime}}{\phi_i^{\prime}}.
  \]
  Components of the vector $\bvec\in\R^n$ are $\bvec_i=\inner{f}{\phi_i}$. We
  note that if $V_h\ni f=\sum_{i=0}^{n-1}\mathbf{F}_i \phi_i$, then
  $\bvec=\Mmat\mathbf{F}$. Here we have introduced the mass matrix $\Mmat$ whose
  components are given by
  \[
    \Mmat_{i, j} = \inner{\phi_j}{\phi_i}.
  \]
  It is clear that properties of mass and stiffness matrices depend on the
  choice of basis functions of $V_h$. We shall briefly summarize how the finite
  dimensional subspace is constructed in each of the methods.
  % For each.  V_h, A, M, convergence properties of the solution! 
  \subsection{Finite element method}
  For given $n\in\mathbb{N}, n>1$, we shall partition a bi-unit interval into
  $n+1$ elements $e_i=\left[x_i, x_{i+1}\right], i=0, 1, \dots, n$ where the
  vertices $x_i$ are such that $-1\leq x_i\leq-1$ for $i=0, 1, \dots, n+1$. Using
  vertices $x_i$ we define for $i=1,2\dots,n$ the hat-functions $\phi_i$,
  \begin{equation}
    \label{eq:hat}
    \phi_i(x)=\begin{cases}
      \frac{x-x_{i-1}}{x_i-x_{i-1}}&\quad x\in e_{i-1},\\
      \frac{x-x_{i+1}}{x_i-x_{i+1}}&\quad x\in e_{i},\\
      0&\quad\text{otherwise}.
               \end{cases}
  \end{equation}
  For notational simplicity we shift the counting index $i\leftarrow i-1$ and
  define $V_n=\spn\left\{\phi_i\right\}_{i=0}^{n-1}$. Clearly we have
  $\text{dim}V_n=n$ and $V_n\subset V$. If the vertices $x_i$ are equidistant
  with spacing $h=\tfrac{2}{n+1}$ the stiffness matrices can be immediately
  written down. Indeed we have
  \[
    \Amat = \frac{1}{h}\begin{bmatrix}
      2 & -1 & 0 & 0 & 0 &\dots & 0 \\
      -1 & 2 & -1 & 0 & 0 &\dots & 0 \\
      0  & -1 & 2 & -1 & 0&\dots & 0 \\
      0  & 0 & \ddots & \ddots & \ddots &\dots & 0\\
      0 & \dots & 0 & -1 & 2 & -1 & 0 \\
      0 & \dots & 0 & 0 & -1 & 2 & -1 \\
      0 & \dots & 0 & 0 & 0 & -1 & 2 \\
          \end{bmatrix}
  \]
  and
  \[
    \Mmat = \frac{h}{6}\begin{bmatrix}
      4 & 1 & 0 & 0 & 0 &\dots & 0 \\
      1 & 4 & 1 & 0 & 0 &\dots & 0 \\
      0  & 1 & 4 & 1 & 0&\dots & 0 \\
      0  & 0 & \ddots & \ddots & \ddots &\dots & 0\\
      0 & \dots & 0 & 1 & 4 & 1 & 0 \\
      0 & \dots & 0 & 0 & 1 & 4 & 1 \\
      0 & \dots & 0 & 0 & 0 & 1 & 4 \\
          \end{bmatrix}
  \]
  Finally we note that the following error estimate holds for the method 
  $\norm{u^{\prime}-u_h^{\prime}}\leq h\norm{u^{\prime}}_2$. The error therefore
  decreases linearly if the mesh size is decreased (or equivalently $n$ is
  increased).

  \subsection{Galerkin method with eigenfunctions}
  We let $\alpha_k=\frac{\pi}{2}+k\frac{\pi}{2}$ for $k=0, 1, \dots$ and
  consider functions $\varphi_k$,
  \[
    \varphi_k(x) = \begin{cases}
                \cos{\alpha_k x} &\quad k \text{ is even },\\
                \sin{\alpha_k x} &\quad k \text{ is odd }.\\
              \end{cases}
  \]
  Clearly $\varphi_k\in V$. Moreover with $\lambda_j=\alpha_j^2$, the functions
  $\varphi_j$ are solutions to the eigenvalue problem: Find $\lambda\in\R, u\in V$
  such that
  \[
    \inner{u^{\prime}}{v^{\prime}} = \lambda \inner{u}{v}\quad\forall v \in V.
  \]
  Finally we note that $\inner{\varphi_i}{\varphi_j}=\delta_{ij}$ and 
  $\inner{\varphi_i^{\prime}}{\varphi_j^{\prime}}=\lambda_j\delta_{ij}$. The
  functions are thus orthonormal in the $L^2$-inner product and orthogonal in
  the $H^1$ inner product. The set $\left\{\varphi_k\right\}_{k=0}^{\infty}$
  forms an orthogonal basis of $V$. In the Galerkin method we shall define the
  finite dimensional space as $V_m=\spn\left\{\varphi_i\right\}_{i=0}^{m-1}$.
  Owing to the orthogonality properties the stiffness and mass matrices
  assembled on $V_m$ take a particularly simple form. We have
  \[
    \Amat_{ij} = \lambda_j\delta_{ij}
    \quad\text{ and }\quad
    \Mmat_{ij} = \delta_{ij}.
  \]
  Finally we note that the following error estimate holds for the method 
  $\norm{u^{\prime}-u_m^{\prime}}\leq \frac{1}{\alpha_m}\norm{f}$ and thus
  we expect the error in the energy norm to decrease linearly with increasing
  $m$.

  \subsection{Galerkin method with Legendre polynomials}
  Let us denote $l_k$ the $k-th$ Legendre polynomial. It is known
  (e.g. \cite{shen_book}) that the boundary values of Legendre polynomials are
  \[
    l_k(1) = 1\quad\text{ and }\quad l_k(-1) = (-1)^k
  \]
  and consequently $l_k\notin V$. However special combinations of Legendre
  polynomials can be taken to yield polynomials that have zero boundary values.
  If $\varphi_k=\beta_k\left(l_{k+2} - l_k\right), k=0, 1,\dots$ with constants
  $\beta_k$ given as $\beta_k = \frac{1}{\sqrt{4k + 6}}$ then
  \cite{shen_leg} showed that the functions are zero on the boundary and
  consequently $\varphi_k\in V$. The functions $\varphi_j$ have desirable
  orthogonality properties, namely
  $\inner{\varphi_i^{\prime}}{\varphi_j^{\prime}}=\delta_{ij}$ and
  $\inner{\varphi_i}{\varphi_j}=0$ for $j\notin\left\{i-2, i, i+2\right\}$.
  For the Galerkin method we set $V_m=\spn\left\{\varphi_i\right\}_{i=0}^{m-1}$
  so that $\text{dim}V_m=m$. As with the eigenfunctions, the matrices assembled
  on $V_m$ have a simple form. The stiffness matrix is in fact an identity
  while the mass matrix is sparse tridiagonal matrix with nonzero entries
  \[
    \Mmat_{ii} = \beta_i^2\left(\frac{2}{2i+1}+\frac{2}{2i+5}\right)
    \quad{\text{ and }}\quad
    \Mmat_{i(i+2)} = -\beta_i\beta_{i+2}\frac{2}{2(i+2)+1}.
  \]
  Finally, owing to the error estimate (\cite{shen_leg})
  \[
    \norm{u-u_m} + (m+1)\norm{u-u_m}_1 \leq C(s)(m+1)^{-s}\norm{u}_s
  \]
  the method converges exponentially for $u\in H^s\left({\Omega}\right)$.

  With the stiffness and mass matrices of all methods in place we shall now
  try to answer a question whether there exists a connections between the
  matrices of the finite element method and the matrices of the other two
  methods. Broadly speaking we are asking for existence of the transformation
  (and possibly its properties) of the global method (in a sense that the
  support of neither eigenfunctions nor the polynomials due to Shen is localized)
  and the local (finite element) method.

  % Now we are interested in connection between FEM(local) and other global
  % matrices/methods
  \section{Eigen connection}
  Consider the finite dimensional space of eigenfunctions $V_m$ and function $f$
  which has zeros on the boundary and is at least $C^0$. We then define $\pi_m f$
  as
  \[
    \pi_m f = \displaystyle\sum\limits_{k=0}^{m-1}c_k \varphi_k,
  \]
  where the coefficients $c_k$ are $c_k=\inner{f}{\phi_k}$. Function $\pi_m$ is
  the usual $L^2$ projection of $f$ onto $V_m$. To test the approximation
  properties of the projection, we have considered functions
  $f_0=e^{2x}(x^4-1)$ and $f_1=e^{2x}(x^4-1)\sin{4\pi x}$ and measured
  convergence rate of $\norm{f_i - \pi_{f_i}}$. The results are shown in
  Figure \ref{fig:eig_smooth_projection}. We see that for the function $f_0$
  which does not oscillate inside the interval, the rate is constant (we
  obtained $k^{-2.15}$ by the least squares fit). On the other hand the rate
  for function $f_1$ behaves as $m^{-2}$ only for $k>10$. The key to this behavior
  is in the right pane of the figure which shows the spectrum of function $f_0,
  f_1$. The first function has a smooth spectrum which decays for all $k$
  ($k^{-2.78}$ by the least squares fit) while the second spectrum decays
  monotonically only for $k>10$.
  \begin{figure}
  \begin{center}
    \includegraphics[width=0.45\textwidth]{img/eigen_smooth_rate.pdf}
    \includegraphics[width=0.45\textwidth]{img/eigen_smooth_power.pdf}
  \end{center}
  \label{fig:eig_smooth_projection}
  \caption{Convergence rate of $\pi f$ for smooth functions. (left) The
  convergence rate in the $L^2$ norm. (right) Magnitude of coefficients $c_k$.}
  \end{figure}

  Since our main interest lies in transformation to finite element method we
  now consider properties of the projection $\pi_m$ for the hat functions
  $\phi_i$( cf. eq (\ref{eq:hat})). In general, for hat function $\phi_i$ we
  have the expansion coefficients of projection $c_k$ given by
  \[
    c_k = \inner{\phi_i}{\varphi_k} =
    \displaystyle\int_{x_{i-1}}^{x_{i}}\frac{x-x_{i-1}}{x_i-x_{i-1}}\varphi_k(x)\meas{x}+
    \displaystyle\int_{x_{i}}^{x_{i+1}}\frac{x-x_{i+1}}{x_i-x_{i+1}}\varphi_k(x)\meas{x}.
  \]
  The above integral can be carried by the integration by parts with the result
  \begin{equation}
    \label{eq:eigen_hat_ck}
    c_k =
    \frac{1}{\alpha_k^2}
    \left(
    \frac{\varphi_k(x_i) - \varphi_k(x_{i-1})}{x_i - x_{i-1}} +
    \frac{\varphi_k(x_{i+1}) - \varphi_k(x_{i})}{x_i - x_{i+1}}
    \right)
  \end{equation}
  To analyze the asymptotic behaviour of $c_k$ we shall consider homogeneous
  mesh with elements of size $h$ and consider special hat functions centered
  at the origin. We shall refer to these as $(-h, 0, h)$. This choice greatly
  simplifies the calculations but it is by no means unreasonable as for the mesh
  with even number of elements such function is always present in $V_n$.

  Since functions $(-h, 0, h)$ are even we have $c_k=0$ for $k$ odd (recall that
  odd wavenumbers belong to sines). For $k$ even expression
  (\ref{eq:eigen_hat_ck}) simplifies to
  \[
    c_k = \frac{4}{\alpha_k^2 h}\sin^2\left(\frac{h}{2}\alpha_k\right).
  \]
  Finally by considering the term
  $\frac{\sin^2\left(\frac{h}{2}\alpha_k\right)}{h}$
  we obtain for $\frac{h}{2}\alpha_k > \frac{\pi}{2}$ or equivalently 
  $k>\tfrac{2}{h}$ the bound on the coefficients
  \[
    c_k \leq \frac{1}{\alpha_k^2}.
  \]
  This implies that for each $h$ there exists a critical wavenumber $k_0=2/h$
  such that for all wavenumbers $k>k_0$ the coefficients should always be 
  smaller the $k^{-2}$.

  The estimate of the critical wavenumber as well as the asymptotic behaviour
  agree well with the numerical experiments whose results are shown in Figure
  \ref{fig:eig_hat_spectrum}. Note that the right pane of the figure showing
  the spectrum of shifted hat functions $(-h+0.1, 0, h)$ also shows the
  asymptotic decay $k^{-2}$.
  \TODO{Maybe add the error plots?}
  \TODO{General estimates for homogeneous mesh.}
  \TODO{There must be a convergence theory for this series.}

  \begin{figure}
  \begin{center}
    \includegraphics[width=0.45\textwidth]{img/eigen_hat_spectrum_centered.pdf}
    \includegraphics[width=0.45\textwidth]{img/eigen_hat_spectrum_off.pdf}
  \end{center}
  \label{fig:eig_hat_spectrum}
  \caption{Spectrum of has function. (left) Dependence of $\inner{f}{\varphi_k}$
    on the wave number for the hat function $(-h, 0, h)$. Vertical lines denote
    the computed wave number $k0$. (right) Dependence of coefficients $c_k$ on
    the wave number for hat function $(-h+0.1, 0.1, h+0.1)$. Note that $c_k=0$
    were excluded from the plot. Both plots confirm the $k^{-2}$ decay.}
  \end{figure}

  Let us denote $V_n, V_m\subset V$ the finite dimensional subspaces of $V$
  constructed respectively by $n$ hat functions $\phi_i$ and by first $m$
  eigenfunctions $\varphi_j$. Further let $\Amat, \Mmat \in \R^{n \times n}$ denote
  the stiffness and mass matrices assembled with on $V_n$. Finally we denote
  by $\Ammatt, \Mmmatt \in \R^{m\times m}$

  \section{CG1 vs Legendre}
  % projection -> smooth
  % even mode
  % any mode
  % the rates for 4, 8, 16, 32

  \bibliographystyle{plain}
  \bibliography{CG_matrices}
\end{document}
